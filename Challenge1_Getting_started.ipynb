{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Getting started <img align=\"right\" src=\"../Supplementary_data/EY_logo.png\" style=\"margin:0px 50px\">\n",
    "\n",
    "Welcome to the 2021 Better Working World Data Challenge! \n",
    "\n",
    "This notebook will show you how to open and explore the data, identify problematic areas of the data, create a basic solution to the problem, and submit your results via the EY Data Science platform.\n",
    "\n",
    "Prior to running this notebook, make sure you have:\n",
    "* **Created a profile** on the [EY Data Science Platform](https://datascience.ey.com/)\n",
    "* **Registered** for \"Challenge 1: Fire mapping\" on the Platform\n",
    "\n",
    "We also recommend checking out the resources in the \"01_Beginners_guide\" folder to learn about jupyter notebooks and the Open Data Cube before coming back here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your task\n",
    "\n",
    "The training dataset contains 129 linescan images (infra-red images taken from an airplane) of bushfires in Victoria, Australia, during the first three months of 2019. There are also polygons showing where the fire is in each image, which have been hand-drawn by our collaborators at the Country Fire Authority (CFA). These polygons are the ground truth your solution should be able to recreate.\n",
    "\n",
    "There are an additional 5 linescan images, the test dataset, where the polygons showing the fire boundaries have not been provided. Your task is to train a model or process which can produce a fire boundary for the remaining 5 linescans with no polygon.\n",
    "\n",
    "All the linescan images (both the traning and test sets) are served via the Open Data Cube python library. The polygons are already available in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and instantiate a datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "\n",
    "from datacube import Datacube\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../scripts\")\n",
    "from dea_plotting import map_shapefile\n",
    "from dea_spatialtools import xr_rasterize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = Datacube(app=\"Getting started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import variables\n",
    "### Import input variable: aerial linescan images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's query the datacube object to identify what linescans are available. We'll also sort them by ID to ensure they're ordered consistently for this guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linescan_datasets = dc.find_datasets(product='linescan')\n",
    "linescan_datasets = sorted(linescan_datasets, key = lambda ds: (ds.center_time, ds.id))\n",
    "\n",
    "sample = linescan_datasets[0]\n",
    "\n",
    "print(sample)\n",
    "print(sample.metadata_doc['label'])\n",
    "\n",
    "print(f'\\nNumber of linescan datasets: {len(linescan_datasets)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results stored in `linescan_datasets` are metadata which describe the various linescan files, including the filename (called the 'label'), extent, date and time of acquisition, and an ID number for that dataset.  Not until we load the dataset can we actually read or view the data. The cell below loads a single linescan from the available list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dc.load(product='linescan', id=linescan_datasets[23].id, output_crs='epsg:28355', resolution=(-10,10))\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.linescan.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'challenge1_train.csv' file lists the names of all the training linescans that are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('resources/challenge1_train.csv', index_col='id')\n",
    "print(train.head())\n",
    "print(f'\\nNumber of training images: {len(train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Target Variable: Fire Map Polygons\n",
    "\n",
    "Let's load and display the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_file = 'resources/fire_boundaries.shp'\n",
    "gdf = gpd.read_file(vector_file)\n",
    "print('Number of objects in geodataframe: ' + str(len(gdf)))\n",
    "gdf.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_col = 'SourceName'\n",
    "map_shapefile(gdf, attribute=attribute_col, fillOpacity=0.2, color=\"yellow\", fillColor=\"red\", default_zoom=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Polygon Dataset\n",
    "While the polygons provided were created from the linescan images, it is not always easy to see exactly which linescan was the source for a given polygon.\n",
    "\n",
    "### Direct matches\n",
    "Looking at the linescan dataset metadata, in many cases the linescan label field can be used to match the linescan to a set of polygons using the SourceName field, with some slight changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linescan_datasets[23].metadata_doc['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf.SourceName[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composite Polygons\n",
    "\n",
    "Another subset of the polygon dataset that will require more careful consideration are polygons derived from multiple linescans. These polygons usually represent larger fires that stretch over many linescan images and are referred to as \"composite polygons\".\n",
    "\n",
    "Identifying these polygons is a little trickier and involves searching the SourceName attribute for the word \"composite\". Some composites might not meet this condition, but will have a list of numbers representing the linescans it was derived from, so in addition to \"composite\", we will also search for commas and the ampersand symbol '&'. \n",
    "\n",
    "The query is as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composites = gdf[gdf.SourceName.str.upper().str.contains(\",|&|(COMPOSITE)\", na=False)]\n",
    "\n",
    "print(f\"Total composite polygons: {len(composites)}\")\n",
    "composites.SourceName.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite there being almost 300 composite polygons, there are only a few distinct SourceName values. You will find the SourceName contains valuable information for matching the polygon to its relevant linescans, such as the fire name, the linescan identifiers and the date and time range over which the polygon covers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composites.SourceName.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Up Polygon Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work on the string formatting first. The format is slightly different between the linescan label field and the polygon SourceName field. The white spaces have been replaced with underscores and the '.jpg' at the end of the filename has been removed, and its in upper case. To clean up the SourceName field in the polygon dataset, first we create a function and test it, and then apply it across the dataset. We also need to make sure we keep in mind that composite SourceNames don't have a '.jpg' at the end, and so should be treated slightly differently.\n",
    "\n",
    "In the same step, we'll also format the datetime fields in the same step as they're currently formatted as strings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    if name is None:\n",
    "        res = None\n",
    "    else:\n",
    "        if name.upper()[-4::] == \".JPG\":\n",
    "            res = name.upper()[:-4].replace(' ','_')\n",
    "        else:\n",
    "            res = name.upper().replace(' ','_')\n",
    "    return res\n",
    "\n",
    "test_string = 'aberfeldy west 200 p1_201901260955_mga94_55.jpg'\n",
    "test_string_composite = 'Composite wallhalla 397,398 & 401 20190225 (1311 to 1342hrs)'\n",
    "print(clean_name(test_string))\n",
    "print(clean_name(test_string_composite))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['SourceNameClean'] = gdf.apply(lambda row: clean_name(row.SourceName), axis=1)\n",
    "gdf.dtUTC = gdf.apply(lambda row: datetime.strptime(row.dtUTC, '%Y-%m-%d %H:%M:%S'), axis=1)\n",
    "gdf.dtLocal = gdf.apply(lambda row: datetime.strptime(row.dtLocal, '%Y-%m-%d %H:%M:%S'), axis=1)\n",
    "gdf.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use the SourceNameClean field to join your polygon dataset to the linescan dataset, for those polygons where there is a direct match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the challenging aspects of the polygon dataset\n",
    "\n",
    "As pointed out in the sections above, there is a subset of polygons that will need more careful consideration if they are to be matched to their relevant linescans. In this guide, we will not attempt to match composite polygons as this process is more involved and is part of the challenge!\n",
    "\n",
    "For contestants that wish to attempt the matching of this set of polygons, it is worth noting that the timestamps on these polygons were manually entered and hence may be prone to inaccuracies. Any matching technique that might involve the timestamp should consider this and perhaps look at applying a time buffer either side, the size of which is a hyperparameter. The larger the time buffer, the more polygons will be matched, but at the risk of matching polygons that are sourced from linescans at a later or earlier time. This means there is a trade-off between the completeness of the matching annotations that are identified, and annotation noise.\n",
    "\n",
    "In addition to the potential for slight errors, the timestamp of composite polygons are ambiguous by nature, so the time range contained within the SourceName (given in local time) should be preferred to the timestamp given in the dtLocal variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare linescan against target polygon\n",
    "\n",
    "Ignoring the challenging aspects of the dataset, let's look at one of the linescans with directly matched polygons and simply select all objects that have the same source file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = linescan_datasets[23].metadata_doc['label']\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {sum(gdf.SourceNameClean == fname)} polygons for linescan {fname}\")\n",
    "\n",
    "ob = gdf.loc[gdf.SourceNameClean == fname]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the polygons over the top of the linescan they were sourced from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = dc.load(product='linescan', id=linescan_datasets[23].id, output_crs='epsg:28355', resolution=(-10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,15))\n",
    "src.linescan.plot(ax=ax)\n",
    "ob.geometry.exterior.plot(ax=ax, edgecolor='red', linewidths=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, our polygons are made from vertices and paths. This is called vector data. By comparison, our linescans are grids of pixel values, called raster data. It may be useful to convert the polygons into a binary raster called a \"mask\", as many machine learning libraries accept masks as input rather than polygons. We can use the `src` variable to define the extent of the mask that is created from any polygons that intersect with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = xr_rasterize(gdf=ob, da=src)\n",
    "tgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `tgt` mask variable contains an array of ones and zeros; ones represent areas inside the polygons and zeroes represent areas outside them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "src.linescan.plot(ax=ax[0])\n",
    "ax[0].set_title('Source: linescan')\n",
    "\n",
    "tgt.plot(ax=ax[1])\n",
    "ax[1].set_title('Target: ground truth mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract fire boundary from raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can extract meaningful information from the linescan image, we need to clean up noise in the image and make the signal clearer. For example, we could threshold the image to mask the data and remove the noise. You can experiment with different strategies including machine learning and feature engineering to find an optimal process. Further guidance can be found in the [Image analysis in python](Image_analysis_in_python.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 220\n",
    "our_mask = src.linescan>threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "our_mask.plot(ax=ax[0])\n",
    "ax[0].set_title('Prediction: our mask')\n",
    "\n",
    "tgt.plot(ax=ax[1])\n",
    "ax[1].set_title('Target: ground truth mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a submission\n",
    "For the five linescans where there is no mask provided, you must first create a mask, and then return one or zero for a specific set of coordinates, where one indicates that coordinate is on fire, and zero indicates it is not.\n",
    "\n",
    "The \"challenge1_test.csv\" file provides a list of 1000 coordinates that are required to be classified for each of these five linescans. You can use the label field to identify the relevant linescan to source your predictions from, or you can use the dateTimeLocal column in combination with the coordinates to load subsets of data directly from the ODC. Note that the coordinates are denoted in the same Coordinate Reference System (CRS) as the linescans and polygons, epsg:28355."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('resources/challenge1_test.csv', index_col='id')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can index into the dataset at particular coordinates to return the value at that address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the coordinates of the centre of the dataset (or any point of interest)\n",
    "x, y = (our_mask.extent.boundingbox.left + our_mask.extent.boundingbox.width // 2 ,\n",
    "        our_mask.extent.boundingbox.top - our_mask.extent.boundingbox.height // 2)\n",
    "print(x, y)\n",
    "\n",
    "# get the value at those coordinates using sel\n",
    "centre_value = our_mask.sel(x = x, y = y, method='nearest').values[0]\n",
    "print(centre_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will iterate over the test set of linescan images, and iterate over the test coordinates required in each image, filling the 'target' column of the test dataframe with the results of the masking process we have developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = test.label.unique()\n",
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 220\n",
    "    \n",
    "for file_stem in fnames:\n",
    "    \n",
    "    # load the linescan data\n",
    "    src = dc.load(product='linescan', label=file_stem, output_crs='epsg:28355', resolution=(-10,10))\n",
    "\n",
    "    # create a mask using the process we developed earlier. For this example, we will simply threshold each linescans\n",
    "    mask = src.linescan>threshold\n",
    "    \n",
    "    # iterate over the coordinates that are required for testing in the current linescan file\n",
    "    for idx, ob in test.loc[test.label==file_stem].iterrows():\n",
    "        result_tf = mask.sel(x=ob.x, y=ob.y, method='nearest').values[0]\n",
    "        result_10 = int(result_tf == True)\n",
    "        test.loc[(test.label==file_stem) & (test.x==ob.x) & (test.y==ob.y), 'target'] = result_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('my_challenge1_submission.csv', columns = ['target'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit your file to the [EY Data Science Platform](https://datascience.ey.com/) for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please review the FAQ section and support options on the [EY Data Science Platform](https://datascience.ey.com/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
